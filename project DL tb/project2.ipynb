{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "38e4f2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "from dnn_app_utils_v3 import *\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "fb4bb6bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(918, 12)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.load('heart_convert2.npy')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "1d7aa4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[:, :11]\n",
    "Y = data[:, 11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "09c0da92",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,Y,test_size=0.2,stratify=Y,random_state=123)\n",
    "Y_train = np.expand_dims(y_train,axis=1)\n",
    "Y_test = np.expand_dims(y_test,axis=1)\n",
    "X_train, X_test, Y_train, Y_test = X_train.T, X_test.T, Y_train.T, Y_test.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "67cf9cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training X:  (11, 734)\n",
      "Training Y:  (1, 734)\n",
      "Testing X:  (11, 184)\n",
      "Testing Y:  (1, 184)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training X: \",X_train.shape)\n",
    "print(\"Training Y: \",Y_train.shape)\n",
    "print(\"Testing X: \",X_test.shape)\n",
    "print(\"Testing Y: \",Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "3f9ccc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_layer_model(X, Y, layers_dims, learning_rate = 0.0075, num_iterations = 3000, print_cost=False):\n",
    "    \"\"\"\n",
    "    Implements a L-layer neural network: [LINEAR->RELU]*(L-1)->LINEAR->SIGMOID.\n",
    "    \n",
    "    Arguments:\n",
    "    X -- data, numpy array of shape (num_px * num_px * 3, number of examples)\n",
    "    Y -- true \"label\" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples)\n",
    "    layers_dims -- list containing the input size and each layer size, of length (number of layers + 1).\n",
    "    learning_rate -- learning rate of the gradient descent update rule\n",
    "    num_iterations -- number of iterations of the optimization loop\n",
    "    print_cost -- if True, it prints the cost every 100 steps\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
    "    \"\"\"\n",
    "\n",
    "    np.random.seed(1)\n",
    "    costs = []                         # keep track of cost\n",
    "    \n",
    "    # Parameters initialization.\n",
    "    parameters = initialize_parameters_deep(layers_dims)\n",
    "    # Loop (gradient descent)\n",
    "    for i in range(0, num_iterations):\n",
    "        # Forward propagation: [LINEAR -> RELU]*(L-1) -> LINEAR -> SIGMOID.\n",
    "        AL, caches = L_model_forward(X, parameters)\n",
    "        # Compute cost.\n",
    "        cost = compute_cost(AL, Y)\n",
    "        # Backward propagation.\n",
    "        grads = L_model_backward(AL, Y, caches)\n",
    "        # Update parameters.\n",
    "        parameters = update_parameters(parameters, grads, learning_rate)\n",
    "                \n",
    "        # Print the cost every 100 iterations\n",
    "        if print_cost and i % 100 == 0 or i == num_iterations - 1:\n",
    "            print(\"Cost after iteration {}: {}\".format(i, np.squeeze(cost)))\n",
    "        if i % 100 == 0 or i == num_iterations:\n",
    "            costs.append(cost)\n",
    "    \n",
    "    return parameters, costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "926ea121",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size = X_train.shape[0]\n",
    "input_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "2f0e4367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.7145645910283833\n",
      "Cost after iteration 100: 0.6834360922110555\n",
      "Cost after iteration 200: 0.6557331264357293\n",
      "Cost after iteration 300: 0.6274022800349438\n",
      "Cost after iteration 400: 0.5968314533090773\n",
      "Cost after iteration 500: 0.5648696243404834\n",
      "Cost after iteration 600: 0.5341054840514188\n",
      "Cost after iteration 700: 0.5066670422741706\n",
      "Cost after iteration 800: 0.4834544104838809\n",
      "Cost after iteration 900: 0.4643163223947682\n",
      "Cost after iteration 1000: 0.44907778091797024\n",
      "Cost after iteration 1100: 0.43729769436462246\n",
      "Cost after iteration 1200: 0.4280830305405836\n",
      "Cost after iteration 1300: 0.4207933042554852\n",
      "Cost after iteration 1400: 0.4150897229776596\n",
      "Cost after iteration 1500: 0.4103896035681442\n",
      "Cost after iteration 1600: 0.40628402731413504\n",
      "Cost after iteration 1700: 0.4026419472183762\n",
      "Cost after iteration 1800: 0.39948573858190367\n",
      "Cost after iteration 1900: 0.3966921956824728\n",
      "Cost after iteration 2000: 0.39412034887020336\n",
      "Cost after iteration 2100: 0.39179692163527247\n",
      "Cost after iteration 2200: 0.3896480663500426\n",
      "Cost after iteration 2300: 0.3876098462540423\n",
      "Cost after iteration 2400: 0.38569924911335024\n",
      "Cost after iteration 2500: 0.3838508050518471\n",
      "Cost after iteration 2600: 0.38213055307314747\n",
      "Cost after iteration 2700: 0.3804508427223138\n",
      "Cost after iteration 2800: 0.3788178530984047\n",
      "Cost after iteration 2900: 0.37722688280441047\n",
      "Cost after iteration 3000: 0.37563039303747825\n",
      "Cost after iteration 3100: 0.3740197039825444\n",
      "Cost after iteration 3200: 0.3725062740916429\n",
      "Cost after iteration 3300: 0.37101418232547795\n",
      "Cost after iteration 3400: 0.3694645430226735\n",
      "Cost after iteration 3500: 0.36803148353969867\n",
      "Cost after iteration 3600: 0.3666652493172535\n",
      "Cost after iteration 3700: 0.36532333212521634\n",
      "Cost after iteration 3800: 0.36405384605328034\n",
      "Cost after iteration 3900: 0.3628439806228805\n",
      "Cost after iteration 4000: 0.3616539855680354\n",
      "Cost after iteration 4100: 0.36045771175113034\n",
      "Cost after iteration 4200: 0.35931193077015644\n",
      "Cost after iteration 4300: 0.3581711347803162\n",
      "Cost after iteration 4400: 0.35706826884524584\n",
      "Cost after iteration 4500: 0.3559604412369883\n",
      "Cost after iteration 4600: 0.3548611136635445\n",
      "Cost after iteration 4700: 0.3537851859295866\n",
      "Cost after iteration 4800: 0.35270988484768023\n",
      "Cost after iteration 4900: 0.35165488136166634\n",
      "Cost after iteration 5000: 0.3505776219358176\n",
      "Cost after iteration 5100: 0.34952215864578606\n",
      "Cost after iteration 5200: 0.34850499744949326\n",
      "Cost after iteration 5300: 0.34757060702143183\n",
      "Cost after iteration 5400: 0.3466493711431744\n",
      "Cost after iteration 5500: 0.3456873232487181\n",
      "Cost after iteration 5600: 0.3446714519511912\n",
      "Cost after iteration 5700: 0.34356219693820084\n",
      "Cost after iteration 5800: 0.3424459825492906\n",
      "Cost after iteration 5900: 0.34133445235945314\n",
      "Cost after iteration 6000: 0.3402719576987666\n",
      "Cost after iteration 6100: 0.33931366697503806\n",
      "Cost after iteration 6200: 0.33833096457436346\n",
      "Cost after iteration 6300: 0.33739068147817014\n",
      "Cost after iteration 6400: 0.3365098530195044\n",
      "Cost after iteration 6500: 0.33564500136353387\n",
      "Cost after iteration 6600: 0.3347826401089568\n",
      "Cost after iteration 6700: 0.333908437383477\n",
      "Cost after iteration 6800: 0.3330611148786292\n",
      "Cost after iteration 6900: 0.33224071502766855\n",
      "Cost after iteration 7000: 0.3314406962079881\n",
      "Cost after iteration 7100: 0.33065664538609746\n",
      "Cost after iteration 7200: 0.3298805139367219\n",
      "Cost after iteration 7300: 0.3291024981008645\n",
      "Cost after iteration 7400: 0.3283123848067185\n",
      "Cost after iteration 7500: 0.32753742226682\n",
      "Cost after iteration 7600: 0.3267508087903053\n",
      "Cost after iteration 7700: 0.325980202686323\n",
      "Cost after iteration 7800: 0.3252281809510218\n",
      "Cost after iteration 7900: 0.32449482832884563\n",
      "Cost after iteration 8000: 0.32379873751527666\n",
      "Cost after iteration 8100: 0.3231345102813713\n",
      "Cost after iteration 8200: 0.3225059319781391\n",
      "Cost after iteration 8300: 0.32188487850523756\n",
      "Cost after iteration 8400: 0.32125880692412023\n",
      "Cost after iteration 8500: 0.32060585215622206\n",
      "Cost after iteration 8600: 0.3199876009047902\n",
      "Cost after iteration 8700: 0.3194206378896777\n",
      "Cost after iteration 8800: 0.3188769629919479\n",
      "Cost after iteration 8900: 0.31833903075345804\n",
      "Cost after iteration 9000: 0.31782568486412166\n",
      "Cost after iteration 9100: 0.3173180933707276\n",
      "Cost after iteration 9200: 0.3167964105790389\n",
      "Cost after iteration 9300: 0.3162756598460287\n",
      "Cost after iteration 9400: 0.3157660781364827\n",
      "Cost after iteration 9500: 0.31525955134271194\n",
      "Cost after iteration 9600: 0.31477651350741753\n",
      "Cost after iteration 9700: 0.31428636323926035\n",
      "Cost after iteration 9800: 0.3137969228911625\n",
      "Cost after iteration 9900: 0.3133115812519899\n",
      "Cost after iteration 10000: 0.31285051774138434\n",
      "Cost after iteration 10100: 0.3123873843794202\n",
      "Cost after iteration 10200: 0.3119383830417247\n",
      "Cost after iteration 10300: 0.3115003611525218\n",
      "Cost after iteration 10400: 0.31106578918783706\n",
      "Cost after iteration 10500: 0.3105674492375939\n",
      "Cost after iteration 10600: 0.3100732454929572\n",
      "Cost after iteration 10700: 0.3096057753045228\n",
      "Cost after iteration 10800: 0.3091285889921545\n",
      "Cost after iteration 10900: 0.30858722754819334\n",
      "Cost after iteration 11000: 0.30797808332671783\n",
      "Cost after iteration 11100: 0.3073425330960316\n",
      "Cost after iteration 11200: 0.30675106274346753\n",
      "Cost after iteration 11300: 0.3061572432376178\n",
      "Cost after iteration 11400: 0.3056175292828993\n",
      "Cost after iteration 11500: 0.30508102287452626\n",
      "Cost after iteration 11600: 0.3045889232509253\n",
      "Cost after iteration 11700: 0.3041085349046708\n",
      "Cost after iteration 11800: 0.3036364924767818\n",
      "Cost after iteration 11900: 0.30317833170040204\n",
      "Cost after iteration 12000: 0.3027100904526461\n",
      "Cost after iteration 12100: 0.3022414625355978\n",
      "Cost after iteration 12200: 0.3017639014717216\n",
      "Cost after iteration 12300: 0.3013184369478473\n",
      "Cost after iteration 12400: 0.3008816107275731\n",
      "Cost after iteration 12500: 0.3004552967207677\n",
      "Cost after iteration 12600: 0.3000517466024066\n",
      "Cost after iteration 12700: 0.29966000504585844\n",
      "Cost after iteration 12800: 0.2992747635300648\n",
      "Cost after iteration 12900: 0.2988981405253802\n",
      "Cost after iteration 13000: 0.2985458824141539\n",
      "Cost after iteration 13100: 0.2982061019172556\n",
      "Cost after iteration 13200: 0.29786627309622576\n",
      "Cost after iteration 13300: 0.29752169412779095\n",
      "Cost after iteration 13400: 0.2971713561028912\n",
      "Cost after iteration 13500: 0.2968330817211746\n",
      "Cost after iteration 13600: 0.2964977426167559\n",
      "Cost after iteration 13700: 0.2961722487758295\n",
      "Cost after iteration 13800: 0.29584677021433103\n",
      "Cost after iteration 13900: 0.29552283877009305\n",
      "Cost after iteration 14000: 0.2951967898883939\n",
      "Cost after iteration 14100: 0.294864785063301\n",
      "Cost after iteration 14200: 0.2945347316493665\n",
      "Cost after iteration 14300: 0.29420326107024003\n",
      "Cost after iteration 14400: 0.29387910098907555\n",
      "Cost after iteration 14500: 0.2935710744182495\n",
      "Cost after iteration 14600: 0.293273842446561\n",
      "Cost after iteration 14700: 0.2929825646812182\n",
      "Cost after iteration 14800: 0.29270252899204313\n",
      "Cost after iteration 14900: 0.29242134880594023\n",
      "Cost after iteration 14999: 0.29214378257377444\n"
     ]
    }
   ],
   "source": [
    "layers_dims = [11, 7, 5, 1] \n",
    "#layers_dims = [11, 16, 4, 1] \n",
    "parameters,costs = L_layer_model(X_train,Y_train,layers_dims, num_iterations = 15000, print_cost = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "e418fa62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8801089918256129\n"
     ]
    }
   ],
   "source": [
    "pred_train = predict(X_train,Y_train, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "b187ff65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8532608695652173\n"
     ]
    }
   ],
   "source": [
    "pred_test = predict(X_test,Y_test, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e85fe3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
